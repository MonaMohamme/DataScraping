{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9844da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from random import randint\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750d2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"93\", \" Not;A Brand\";v=\"99\", \"Chromium\";v=\"93\"',\n",
    "    'accept': 'application/json, text/plain, */*',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'accept-language': 'en-US,en;q=0.9'\n",
    "}\n",
    "url_dict = {'us': 'USA_DATA',\n",
    "           'sa':'SAUDIARABIA_DATA',\n",
    "           'de':'GERMANY_DATA',\n",
    "           'fr':'FRANCE_DATA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db369015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(data, file_name):\n",
    "    tem = url.split('/')\n",
    "    tem = tem[-1].split('.')\n",
    "    url_value = tem[0]\n",
    "    directory = url_dict[url_value]\n",
    "    path = os.path.join(os.getcwd(), directory)\n",
    "    # print(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    this_dir = path\n",
    "    # print('cwd: ', this_dir)\n",
    "    file_path = os.path.join(this_dir, file_name + '.csv')\n",
    "    with open(file_path, 'a', newline='') as csvfile:  # works on windows issue also maybe!?\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        row = []\n",
    "        # our data can be either list or dictionary\n",
    "        if isinstance(data, dict):\n",
    "            # if dictionary getting the values\n",
    "            for key, value in data.items():\n",
    "                temp = [key, value]\n",
    "                row.append(temp[1])\n",
    "        elif isinstance(data, list):\n",
    "            row = data\n",
    "\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "def delete_csv(file_name):\n",
    "    tem = url.split('/')\n",
    "    tem = tem[-1].split('.')\n",
    "    url_value = tem[0]\n",
    "    directory = url_dict[url_value]\n",
    "    path = os.path.join(os.getcwd(), directory)\n",
    "    this_dir = path\n",
    "    file_path = os.path.join(this_dir, file_name+'.csv')\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebed655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    source = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(source.text, 'lxml')\n",
    "    ul = soup.find('ul', class_='pure-menu-list')\n",
    "    details = ul.findAll('details')\n",
    "    detail = details[0]\n",
    "    file_name = detail.summary.text\n",
    "\n",
    "    tr = detail.table.tbody.findAll('tr')\n",
    "    header = []\n",
    "    field = []\n",
    "    data = []\n",
    "    count = 1\n",
    "    for t in tr:\n",
    "        td = t.findAll('td')\n",
    "        td.pop(1)\n",
    "        header.append(td[0].text.replace('\\xa0', ''))\n",
    "        field.append(td[-1].text)\n",
    "    data.append(header)\n",
    "    data.append(field)\n",
    "    # print(header)\n",
    "    # print(field)\n",
    "    # print()\n",
    "    # print(url)\n",
    "    tem = url.split('/')\n",
    "    tem = tem[-1].split('.')\n",
    "    url_value = tem[0]\n",
    "    directory = url_dict[url_value]\n",
    "    path = os.path.join(os.getcwd(), directory)\n",
    "    if os.path.exists(os.path.join(path, file_name+'.csv')):\n",
    "        # print('heppend')\n",
    "        delete_csv(file_name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    for d in data:\n",
    "        write_csv(d, file_name)\n",
    "    details.pop(0)\n",
    "\n",
    "\n",
    "    for d in details:\n",
    "        first_header = d.summary.text\n",
    "        header = []\n",
    "        data = []\n",
    "        first_header = d.summary.text\n",
    "        header.append(first_header)\n",
    "        table = d.table\n",
    "        thead = table.thead\n",
    "        td_h = thead.tr.findAll('td')\n",
    "        td_h.pop(0)\n",
    "        for h in td_h:\n",
    "            header.append(h.text.strip())\n",
    "        data.append(header)\n",
    "        tr = table.tbody.findAll('tr')\n",
    "        if os.path.exists(os.path.join(path, first_header +'.csv')):\n",
    "            # print('heppend')\n",
    "            delete_csv(first_header)\n",
    "        for t in tr:\n",
    "            td = t.findAll('td')\n",
    "            header = []\n",
    "            for d in td:\n",
    "                dt = d.text.replace('\\xa0', '')\n",
    "                header.append(dt.replace('     ',''))\n",
    "            data.append(header)\n",
    "        # print('total data:', data)\n",
    "        for d in data:\n",
    "            write_csv(d, first_header)\n",
    "    # print(header)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d33940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data..\n",
      "scraping finished.\n"
     ]
    }
   ],
   "source": [
    "urls = ['https://data.un.org/en/iso/sa.html', 'https://data.un.org/en/iso/de.html', 'https://data.un.org/en/iso/fr.html', 'https://data.un.org/en/iso/us.html']\n",
    "print('getting data..')\n",
    "for url in urls:\n",
    "    time.sleep(randint(3,7))\n",
    "    get_info(url)\n",
    "print('scraping finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262b5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25342ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaef4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
